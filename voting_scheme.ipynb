{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load output test probabilitites and true labels for each model\n",
    "\n",
    "For every model there are 2 files generated in numpy binary format:\n",
    "\n",
    "  **probabilities.npy** - numpy array of size **TEST POINT CLOUDS CLOUD x CLASSES COUNT x MODELS COUNT** with output classification probability for each of 10 individually trained models\n",
    "\n",
    "  **true_labels.npy** - numpy array of size **TEST POINT CLOUDS CLOUD** with true labels data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base models\n",
    "BASE_MODELS = ['pointnet', 'pointnet++', 'so-net', 'kcnet', 'deepsets', 'dgcnn', 'pointcnn']\n",
    "BASE_MODELS_ALIASES = ['PointNet', 'PointNet++', 'SO-Net', 'KCNet', 'DeepSets', 'DGCNN', 'PointCNN']\n",
    "\n",
    "CLASS_NAMES = ['airplane', 'bathtub', 'bed', 'bench', 'bookshelf', 'bottle', 'bowl',\n",
    "               'car', 'chair', 'cone', 'cup', 'curtain', 'desk', 'door', 'dresser',\n",
    "               'flower_pot', 'glass_box', 'guitar', 'keyboard', 'lamp', 'laptop',\n",
    "               'mantel', 'monitor', 'night_stand', 'person', 'piano', 'plant', 'radio',\n",
    "               'range_hood', 'sink', 'sofa', 'stairs', 'stool', 'table', 'tent', 'toilet',\n",
    "               'tv_stand', 'vase', 'wardrobe', 'xbox']\n",
    "CLASS_TEST_INSTANCES = [100, 50, 100, 20, 100, 100, 20, 100, 100, 20, 20, 20, 86, 20,\n",
    "                        86, 20, 100, 100, 20, 20, 20, 100, 100, 86, 20, 100, 100, 20,\n",
    "                        100, 20, 100, 20, 20, 100, 20, 100, 100, 100, 20, 20]\n",
    "CLASSES_COUNT = 40\n",
    "\n",
    "probabilities = {}\n",
    "true_labels = {}\n",
    "for model in list(set(BASE_MODELS) - {'deepsets'}):\n",
    "    for dir_name in ['models_reordered']:\n",
    "        if os.path.exists(os.path.join(dir_name, model)):\n",
    "            break\n",
    "    prob_filepath = os.path.join(os.path.join(dir_name, model), 'probabilities.npy')\n",
    "    label_filepath = os.path.join(os.path.join(dir_name, model), 'true_labels.npy')\n",
    "    probabilities[model] = np.load(prob_filepath)\n",
    "    if dir_name != 'models_reordered':\n",
    "        probabilities[model] = np.transpose(probabilities[model], axes=(2, 0, 1))\n",
    "\n",
    "    # probabilities[model] =  softmax(probabilities[model])\n",
    "    idx = np.argmax(probabilities[model], axis=-1)\n",
    "    hardvote = np.squeeze(np.eye(40)[idx.reshape(-1)]).reshape(probabilities[model].shape)\n",
    "    e_x = np.exp(probabilities[model])\n",
    "    softvote = e_x /np.expand_dims(np.sum(e_x, axis=-1), axis=-1)\n",
    "    probabilities[model] = {'activations': probabilities[model]/np.std(probabilities[model]),\n",
    "                           'hardvote': hardvote, 'softvote': softvote}\n",
    "    true_labels[model] = np.load(label_filepath)\n",
    "    \n",
    "    for class_idx in range(CLASSES_COUNT):\n",
    "        error_info = (\"Test cloud instances for model \" + model + \" and class \"\n",
    "                      + str(class_idx) + \" differs! Should be \" + str(CLASS_TEST_INSTANCES[class_idx])\n",
    "                      + \" but got \" + str(np.sum(true_labels[model] == class_idx)))\n",
    "        assert np.sum(true_labels[model] == class_idx) == CLASS_TEST_INSTANCES[class_idx] or \\\n",
    "          (model=='deepsets' and class_idx==12 and np.sum(true_labels[model] == class_idx) == 85) or \\\n",
    "          (model=='deepsets' and class_idx==39 and np.sum(true_labels[model] == class_idx) == 19) or \\\n",
    "          (model=='deepsets_ep100' and class_idx==12 and np.sum(true_labels[model] == class_idx) == 85) or \\\n",
    "          (model=='deepsets_ep100' and class_idx==39 and np.sum(true_labels[model] == class_idx) == 19), \\\n",
    "          error_info\n",
    "                \n",
    "#     assert (probabilities[model].shape[0] == ENSEMBLE_MODELS_NUMBER)\n",
    "    assert (probabilities[model]['activations'].shape[1] == 2468 or \\\n",
    "            (model=='deepsets' and probabilities[model]['activations'].shape[1] == 2466) or \\\n",
    "           (model=='deepsets_ep100' and probabilities[model]['activations'].shape[1] == 2466))\n",
    "    assert (probabilities[model]['activations'].shape[2] == CLASSES_COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data storage\n",
    "\n",
    "Probabilites variable is built as follows:\n",
    "\n",
    "{ architecture: { voting_scheme :  np.array of shape (I, N, C) }}\n",
    "\n",
    "where:\n",
    " - I : individually trained model index - 10 training sessions were performed for the purpose of the article\n",
    " - N : point cloud index - 2468 point clouds of the ModelNet40 dataset\n",
    " - C : output score for each class - 40 classe of the ModelNet40 dataset\n",
    " \n",
    "To get output scores (activations) of pointnet architecture of the 1st trained model for 2nd point cloud one could type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.38172345 -2.9630289  -0.80163084 -1.05714054 -1.5360259  -2.40504191\n",
      " -2.63470039 -1.76463509 -0.8810986  -3.13946185 -2.85106899 -1.76320127\n",
      " -1.64205964 -2.48452647 -2.0369712  -1.29412171 -3.26203028 -0.49520191\n",
      " -1.22266408 -1.37084027 -0.75889169 -2.28655464 -1.77262273 -1.95681976\n",
      " -1.95408498 -1.57441291 -0.57651098 -1.13647426 -2.014743   -1.40387915\n",
      " -1.02323273 -0.45883906 -1.7262892  -1.43027417 -1.23201494 -1.16588141\n",
      " -1.12470238 -1.90964392 -2.83403742 -1.66838613]\n"
     ]
    }
   ],
   "source": [
    "print (probabilities['pointnet']['activations'][0][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
